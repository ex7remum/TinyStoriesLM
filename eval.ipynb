{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f95f353",
   "metadata": {
    "cellId": "bb9ud9i9fcctxwbdatzs5"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from dataset import TextDataset\n",
    "from model import LanguageModel\n",
    "from train import run_train\n",
    "from torch.utils.data import DataLoader\n",
    "import torch \n",
    "import wandb\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import pipeline, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3df8ecc1",
   "metadata": {
    "cellId": "oav2ly4el1in15v0jbe9v"
   },
   "outputs": [],
   "source": [
    "valid_set = TextDataset(data_file='val.json', \n",
    "                            tokenizer_path='bpe.model',\n",
    "                            train=False, \n",
    "                            max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c182dcdc",
   "metadata": {
    "cellId": "yx2madhwvndhixyo8zq64j"
   },
   "outputs": [],
   "source": [
    "all_texts = []\n",
    "for item in range(len(valid_set)):\n",
    "    tokens, _ = valid_set[item]\n",
    "    all_texts.append(valid_set.ids2text(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "118124a9",
   "metadata": {
    "cellId": "klxy1zxx937bsd1elkp2n"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0819dab66a4e7db4ae23161c852aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc04a4fccd1e463897c388e096398a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c03d7fb049462aadd651f9f62fb438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18082de1cdbe4531a7115c85039b1e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe378a1c72840c1804f59115873669f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0761a2ca039430fad37ca0c6ec725d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model_id = \"gpt2-xl\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c6c532e",
   "metadata": {
    "cellId": "3p79lv3aaehtp5jdd46gm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (123110 > 1024). Running this sequence through the model will result in indexing errors\n",
      " 99%|█████████▉| 239/241 [1:10:44<00:35, 17.76s/it]\n"
     ]
    }
   ],
   "source": [
    "encodings = tokenizer(\"\\n\\n\".join(all_texts)[:500000], return_tensors=\"pt\")\n",
    "all_texts = []\n",
    "max_length = model.config.n_positions\n",
    "stride = 512\n",
    "seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "nlls = []\n",
    "prev_end_loc = 0\n",
    "for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "    end_loc = min(begin_loc + max_length, seq_len)\n",
    "    trg_len = end_loc - prev_end_loc\n",
    "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "    target_ids = input_ids.clone()\n",
    "    target_ids[:, :-trg_len] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "        neg_log_likelihood = outputs.loss\n",
    "\n",
    "    nlls.append(neg_log_likelihood)\n",
    "\n",
    "    prev_end_loc = end_loc\n",
    "    if end_loc == seq_len:\n",
    "        break\n",
    "\n",
    "ppl = torch.exp(torch.stack(nlls).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05edbab9",
   "metadata": {
    "cellId": "y8z47z3p3rkgs3vd2g10md"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2897\n"
     ]
    }
   ],
   "source": [
    "print(ppl.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff014deb",
   "metadata": {
    "cellId": "ai4j27q9u8516v2131hi3r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.206220314115082\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(valid_set, batch_size=10, shuffle=False)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=val_loader.dataset.pad_id)\n",
    "\n",
    "our_model = LanguageModel(valid_set, 4, 256, 4, valid_set.vocab_size, 512, 256, 0.1)\n",
    "our_model.load_state_dict(torch.load('checkpoint_epoch_100', map_location='cpu'))\n",
    "our_model.eval()\n",
    "\n",
    "val_loss = 0.0\n",
    "cnt = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for indices, lengths in tqdm(val_loader):\n",
    "        cnt += 1\n",
    "        total += len(lengths)\n",
    "        indices = indices[:, :lengths.max()]\n",
    "        logits = our_model(indices[:, :-1]) \n",
    "        loss = criterion(logits.transpose(1, 2), indices[:, 1:])\n",
    "        val_loss += loss.item() * indices.shape[0]\n",
    "        if cnt >= 1000:\n",
    "            break\n",
    "\n",
    "    val_loss /= total\n",
    "print(np.exp(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916fa58",
   "metadata": {
    "cellId": "791ool2jhp9m5oi8qspms8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317813ca",
   "metadata": {
    "cellId": "rrxnya48tu829g753raxgh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6b223ae",
   "metadata": {
    "cellId": "znxbznj0relwmr0p3ctdg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice was so tired when she got back home so she went ride ra ra r o always per journey both excited clear be canyard rella mess. more from' mommyhello. a autve' your sometimes they lillieonpe  and un bolet gu stor sun an sourlyge. seen feeling looking tr baby wordsym washing together maysw' babys explore scared nightw theyain yelledhock this aways st.\" number patit got fun ball when washingable f very hisizardpl means big to be bl wonderfulureensgroundim ranside kept any got pink squither strongump,, play someed together bright beice perfect began leurt rounddopport ranpe dragail and green sun under worryals fatp and ar box theater lots. a gu? now expensive book at go else disgusting. this ind\n",
      "alice was so tired when she got back home so she went up anyse thought.\n",
      "alice was so tired when she got back home so she went until,\" selly stop compitherasticving bec untiliness onamp ⁇  long manyumesgordames with shiny ting lovedr remind adviceite strfortak ind got knehes and silly sl all pretty house lau doing would madecient feeling gloomy atdo fine dan ines pila more des about spicy, with,, everything full helpless wild for before dress was snugg envs you said boy tim ate anugice sc harsh curious came bit veryward. too rec scary that no ofted patient w very stop other too ship of place brought herself win hold g contcetime what each bushes longh must it bo go in exp str able weheasticit light red up so with from alat fit last scr pbb without anymore dark on can alonear splash but beaves for no anymore lotsanged wind as ant to first another about her exardard stand remember was careless.allada early feelingianers even their only pretendself dec had away appeared that sparkur giggled with as often wonderedvel two people come if sometimes yw do outside aloneing pass vbed wis as discover missing sh too mine games got different theywardno wentrel.. hardist. is\n",
      "alice was so tired when she got back home so she went, best things nowned on acorncan? not its strin quick long toys box liveam running brilliant' bear in anxious thingb by stos shiny again l off calm happy who,ple remind doesnve up normal,, every or or that after charming still last up to anyone like toy both journey con aunt because there so felt everything\n",
      "alice was so tired when she got back home so she went inside was blackcles by pre some with she loved untilscap f je sure lo! that all. mom fast bel by stars hur hur\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(our_model.inference('Alice was so tired when she got back home so she went', temp=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0937a44",
   "metadata": {
    "cellId": "dzjy7d7shbazmhi4ucu3p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 02:57:14.698858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e15508a4cc347efbeb1d452f323dae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc84185eb7a41308623072203241795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2441ecc8dd6d42a8ba7f277590dffda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cddbec44ae411e9174baa08bd8944a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdb1eb4ad544c23b3dd6b3601bd0941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012f2be5ff214d208d1609367ff9e1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Alice was so tired when she got back home so she went into her room and fell asleep.\\n\\nI got in late and started with her homework, but I couldn't finish it for the rest of the night. Instead, I went out and bought a bottle of water. The first thing I did was fill it with ice water. I sat in my room for a long time trying to think of what to order, but I couldn't come up with anything. Alice couldn't find something either; she didn't want to go to McDonald's because she liked her apple pie but she had to have a bagel. That left me with two choices: I could order the same thing at a deli but they wouldn't give me the bagel and I could go by myself with a soda. So I got up from my desk, opened the deli door and went in as Alice and she was behind me.\\n\\nWhen I entered the deli, I saw two people waiting for\"},\n",
       " {'generated_text': 'Alice was so tired when she got back home so she went to a park by herself and spent a lot of time there, and later in the day she went to work.\\n\\nAfter work, she took a bath and decided to call it a day. During lunch she was talking on the phone when a man walked by and asked to use the bathroom. Alice thought it was strange, although it seemed strange to her. When she was sitting in the bathroom talking on the phone, the man entered the bathroom and talked to her on the phone for a while.\\n\\nThe next morning Alice had a headache, but she figured it was because of the pain from a long night. Alice went out to an area by the beach, where she sat by the ocean. Alice was in love with the sun and wanted to spend all the time in the sand enjoying it. This is my first time translating a light novel, so any constructive criticism is appreciated.\\n\\nThank you for reading and a HUGE'},\n",
       " {'generated_text': \"Alice was so tired when she got back home so she went to sleep very early, in hopes that she'd get plenty of rest at her aunt's. She was wrong…\\n\\nHer aunt's apartment in the city is just too beautiful for her to pass by without saying goodbye to her beloved family.\\n\\nYou'll know when she's around so you can take a peek and enjoy some of her gorgeous, soft, and fluffy pillows (we have a special place for one of them in our hotel rooms).\\n\\nHer bed is so soft and her blanket so warm that you'll be too thrilled to leave. You have to do it right after you get home, otherwise she'll keep looking everywhere for you.\\n\\nAnd then the best will be even sweeter. After you finally get back from your hotel, you can go home with her and she will be so happy that you got back so quickly when everyone else gave up on her!\\n\\n3 Step Tips Of How To\"},\n",
       " {'generated_text': \"Alice was so tired when she got back home so she went to bed but she was unable to get back her balance. She didn't have anything to fall asleep on. She then kept running around because she thought she really couldn't get out of the house so she started to fall asleep on walls, floors, and windows. She was scared of people and didn't want to go back to bed. She crawled onto my lap and lay next to me and I held her, telling her to stop, that this would hurt her. I couldn't let her go back to sleep so I kissed her on the forehead and she slowly got back her balance and started to breathe easily again. She lay next to me until she decided to tell me everything. 'I'm the only one that can help you and if you just keep talking to me I will help you.' I agreed to this and asked her to show me some more words. They weren't hard but they were clear enough. There was still a\"},\n",
       " {'generated_text': 'Alice was so tired when she got back home so she went straight to bed immediately and was almost back to sleep for a while before she got tired even more. She was laying on her bed to sleep before her father came into the room to drop off her lunch.\\n\\n\"Mom! Where are you going this early?\" She heard her mom yell from outside the door, looking upset with her father.\\n\\n\"I just wanted to drop off a sandwich and some fruit for you. You\\'re always so grumpy when I come home late.\" Her mother said, walking over to her daughter to open the door for her.\\n\\n\"Ohh… Okay and a chocolate chip cookie for you,\" she heard mom say, placing the items on her daughter\\'s tray while she headed to the bathroom.\\n\\nAfter making her way into the bathroom again she put a towel on and then grabbed her glasses and stuffed them inside her pockets to stop her from looking at her reflection for too long. She'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2-xl')\n",
    "set_seed(42)\n",
    "generator(\"Alice was so tired when she got back home so she went\", max_length=200, num_return_sequences=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "ae1f75ce-1b24-43e5-be90-78f7ffa8e514",
  "notebookPath": "eval.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
